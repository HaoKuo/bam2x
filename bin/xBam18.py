#!/usr/bin/env python
# Programmer : zhuxp
# Date: 
# Last-modified: 12-18-2013, 18:35:23 EST
VERSION="0.1"
import os,sys,argparse
from xplib.Annotation import Bed
from xplib import TableIO,Tools,DBI
from xplib.Tools import IO
import signal
signal.signal(signal.SIGPIPE,signal.SIG_DFL)
import gzip
import time
import xplib.Turing.TuringCodeBook as cb
from xplib.Turing.TuringUtils import *
from xplib.Turing import TuringCode,TuringGraph
from bitarray import bitarray
from networkx.algorithms.approximation.clique import max_clique
import networkx as nx
from networkx.algorithms.clique import find_cliques

'''
Query bam and splicing sites
Construct Turing Graph
and translate reads into BitStr

count reads number in each BitStr
v12:
penalty for increase the number of isoform
v14: 
improve: merging reads with splicing sites first. add mysort

         TODO: reads splicing sites is less than +- 5 bp will merging together
         TODO: reads extends site less than given percentage are treated as unknown?
         TODO: punish by the isoform lengths , instead of the isoform number.
v17: scort by (intron number + 1) * frag_numbers
v18: add rgb color
'''
def ParseArg():
    ''' This Function Parse the Argument '''
    p=argparse.ArgumentParser( description = 'Example: %(prog)s -h', epilog='Library dependency : xplib')
    p.add_argument('-v','--version',action='version',version='%(prog)s '+VERSION)
    p.add_argument('-i','--input',dest="input",default="stdin",type=str,help="input file DEFAULT: STDIN")
    p.add_argument('-I','--input_format',dest="format",default="bed",type=str,help="input file format")
    p.add_argument('-o','--output',dest="output",type=str,default="stdout",help="output file DEFAULT: STDOUT")
    p.add_argument('-s','--splicing_sites',dest="splicing_sites",type=str,help="splicing sites [tabix file] [ output of xBamToSplicingSites.py ]")
    p.add_argument('-b','--bam',dest="bam",type=str,help="bam file")
    p.add_argument('-S','--strand',dest="strand",type=str,choices=["read1","read2"],default="read2",help="bam file")
    #p.add_argument('-t','--threshold',dest="threshold",type=float,default=0.95,help="cutoff for interpret fragments percentage, default: 0.95 ")
    p.add_argument('-m','--min_uniq_percentage',dest="min_uniq",type=float,default=0.02,help="min uniq percentage [ add an isoform only if it can interpret more than min uniq percentage fragments ], default: 0.02 ")
    p.add_argument('-f','--min_uniq_fpk_increase',dest="min_uniq_fpk_increase",type=float,default=0.2,help="default: 0.2 ")
    p.add_argument('-p','--merge_mismatch_bp',dest="merge_bp",type=float,default=0.2,help="default: 0.2 ")
    if len(sys.argv)==1:
        print >>sys.stderr,p.print_help()
        exit(0)
    return p.parse_args()
def Main():
    '''
    IO TEMPLATE
    '''
    global args,out,dbi_splicing,dbi_bam,g
    global h,hc
    MAX_ITER_PATH_NUMBER=10000
    args=ParseArg()
    MIN_FPK_RATIO=args.min_uniq_fpk_increase #TO TEST
    fin=IO.fopen(args.input,"r")
    out=IO.fopen(args.output,"w")
    '''
    END OF IO TEMPLATE 
    '''
    print >>out,"# This data was generated by program ",sys.argv[0]," (version: %s)"%VERSION,
    print >>out,"in bam2x ( https://github.com/nimezhu/bam2x )"
    print >>out,"# Date: ",time.asctime()
    print >>out,"# The command line is :"
    print >>out,"#\t"," ".join(sys.argv)
    header=["chr","start","end","id","score","strand","seq"];
    dbi_splicing_sites=DBI.init(args.splicing_sites,"tabix",tabix="metabed",header=header);
    dbi_bam=DBI.init(args.bam,"bam",method="bam2")


    for i0,i in enumerate(TableIO.parse(fin,args.format)):
        print >>out,"BEGIN\nQR\t",i
        l=list()
        l.append(TuringCode(0,cb.ON))
        l.append(TuringCode(0,cb.BLOCKON))
        l.append(TuringCode(len(i),cb.OFF))
        l.append(TuringCode(len(i),cb.BLOCKOFF))
        for j in dbi_splicing_sites.query(i):
            '''
            To Do query read2
            '''
            code=Tools.translate_coordinates(i,j)
            print >>out,"CODE\t",code
            if code.strand=="+":
                if code.id[0]=="a":
                    l.append(TuringCode(code.start+2,cb.BLOCKON))
                if code.id[0]=="d":
                    l.append(TuringCode(code.start,cb.BLOCKOFF))
        g=TuringGraph(l)
        bitarray_path=bitarray(2*len(g))
        bitarray_path.setall(True)
        print >>sys.stderr,"processing",i0," entry:",i
        print >>out,"FIGURE\t",g.graph_str(600)
        paths_number=g.count_paths_number()
        print >>out,"PATH_NUMBER\t",paths_number
        print >>sys.stderr,"path number:",paths_number
        h={}
        hc={}
        j0=0;
        total_frag=0
        for j in dbi_bam.query(i,method="bam2",strand=args.strand):
            p=[]
            for k in j:
                p.append(TuringFactory(Tools.translate_coordinates(i,k)))
            a=g.translate_paths_into_bits(p,args.merge_bp)
            if isSelfIncompatible(a): continue
            if h.has_key(a.tobytes()):
                h[a.tobytes()]+=1
                if hc[a.tobytes()]!=a:
                    print >>sys.stderr,"WARNING"
            else:
                h[a.tobytes()]=1
                hc[a.tobytes()]=a
            j0+=1
        print >>out,"PATTERN_NUMBER\t",len(h.keys())
        print >>out,"FRG_NUMBER\t",j0
        total_frag=j0
        print >>sys.stderr,"fragments number:",j0
        print >>sys.stderr,"path pattern number:",len(h.keys())
        #sorted_keys=sorted(h,key=h.get,reverse=True)    
        sorted_keys=sorted(h.keys(),cmp=mySort,reverse=True)    
        clique=[]
        cliques=[clique]
        bits=bitarray(len(g)*2)
        bits.setall(True)
        cliques_pattern=[bits]
        for j,key in enumerate(sorted_keys):
            print >>out,"No."+str(j),"\t",hc[key],h[key],bitarray_to_intron_number(hc[key])
            joined_clique=False
            for m,clique in enumerate(cliques):
                if isCompatible(cliques_pattern[m],hc[sorted_keys[j]]):
                    joined_clique=True
                    cliques[m].append(j)
                    cliques_pattern[m]=bitarray_and(cliques_pattern[m],hc[sorted_keys[j]])
                    break
            if not joined_clique:
                clique=[]
                bits=bitarray(len(g)*2)
                bits.setall(True)
                max_index=0
                clique.append(j)
                bits=bitarray_and(bits,hc[sorted_keys[j]])
                cliques.append(clique)
                cliques_pattern.append(bits)
        print >>out,"OUTPUT"

        cumulative_score=0
        #update all cliques pattern.
        j0=0
        #buffer_keys=[] # those key are ignored in previous uniqs
        max_uniq_fpk=0.0
        max_uniq=0
        for j,x in enumerate(cliques):
            score=0
            c=[] 
            for k,y in enumerate(sorted_keys):
                if isCompatible(cliques_pattern[j],hc[y]):
                    cliques_pattern[j]=bitarray_and(cliques_pattern[j],hc[y])
                    score+=h[y]
                    c.append(k)
            cliques_pattern[j][-1]=True
            cliques_pattern[j][-2]=True
            uniq_score=0
            for k,y in enumerate(x):
                uniq_score+=h[sorted_keys[y]]
            '''
            for k,y in enumerate(buffer_keys):
                if isCompatible(cliques_pattern[buffer_keys[k]],
                    cliques[j].append(k)
            '''
            if float(uniq_score)/total_frag < args.min_uniq :
                print >>sys.stderr,"ignore due to small uniq frags:",float(uniq_score)/total_frag
                continue
            else:
                bed=g.translate_bits_into_bed(cliques_pattern[j])
                cdna_length=bed.cdna_length()
                if cdna_length==0:
                    print >>sys.stderr,"ignore due to cdna_length",bed
                    continue
                uniq_fpk=float(uniq_score)/cdna_length*1000.0
                if  uniq_fpk > max_uniq_fpk:
                    max_uniq_fpk=uniq_fpk
                if uniq_fpk  < max_uniq_fpk * MIN_FPK_RATIO:
                    print >>sys.stderr,"ignore due to fpk",bed,"\tuniq_fpk:",uniq_fpk,"\t current max:",max_uniq_fpk
                    continue
                
                rgb=255-uniq_score*240/total_frag  
                cumulative_score+=uniq_score
                j0+=1
                print >>out,"NO."+str(j0)+" CLIQUE"    
                print >>out,"CLIQUE\t",c,"\nUNIQ\t",cliques[j],"\nPATTERN\t",cliques_pattern[j]
                
                bed=g.translate_bits_into_bed(cliques_pattern[j])
                bed.score=score*1000.0/bed.cdna_length()
                bed.chr=i.id
                bed.id=i.id+"_"+"NO."+str(j0)
                bed.itemRgb=str(rgb)+","+str(rgb)+","+str(rgb)
                print >>out,"UNIQ_FRG\t",uniq_score
                print >>out,"TOTAL_FRG\t",score
                print >>out,"UNIQ_FPK",uniq_fpk
                print >>out,"FPK(SCORE)",bed.score
                print >>out,"TR\t",bed

                print >>out,"UNIQ\t",uniq_score,"\tBED\t",Tools.translate_coordinates(i,bed,True)
                #print >>sys.stderr,"UNIQ_FPK/CURRENT_MAX_UNIQ_FPK",uniq_fpk/max_uniq_fpk

                print >>out,""
        print >>out,"INTEPRET FRG\t",float(cumulative_score)/total_frag
        print >>sys.stderr,"INTEPRET FRG\t",float(cumulative_score)/total_frag
        print >>out,"END"
        print >>out,""
        print >>out,""



        
def mySort(x,y):
    #return bitarray_to_intron_number(hc[x])-bitarray_to_intron_number(hc[y]) or h[x]-h[y]
    return bitarray_to_intron_number(hc[x])*h[x]-bitarray_to_intron_number(hc[y])*h[y]  or h[x]-h[y]
    
    
def network_construct(bitarray_paths):
    G=nx.Graph()
    G.add_nodes_from(bitarray_paths)
    for i in bitarray_paths:
        for j in bitarray_paths:
            if isCompatible(i,j):
                G.add_edge(i,j)
    return G


def count_xor(path):
    s=0
    for i in range(0,len(path),2):
        if path[i]^path[i+1]: s+=1 # ^ is xor 
    return s        

def isCompatible(pathA,pathB):  ##pathA and B shoulc be same length
    for i in range(0,len(pathA),2):
        if not (pathA[i]&pathB[i] | pathA[i+1]&pathB[i+1]):
            return False
    return True
def isSelfIncompatible(pathA):
    for i in range(0,len(pathA),2):
        if not pathA[i]:
            if not pathA[i+1]:
                return True
    return False

def isOverlap(pathA,pathB):   ## Fir paired end reads overlap is not start > stop, overlap definition is not the same as overlap reades
    for i in range(0,len(path),2):
        if (pathA[i]^pathA[i+1]) and (pathB[i]^pathB[i+1]):
            return True
    return False

def findConsensusPath(paths):
    pass
    
if __name__=="__main__":
    Main()

